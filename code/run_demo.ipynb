{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import general classes\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import model classes for training and plotting\n",
    "# class that trains all the models\n",
    "from train_model.train_model import train_model\n",
    "# class that visualizes the learned movemes\n",
    "from utilities.utilities import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path variables\n",
    "## DATASET_PATH: path to the dataset with the annotations\n",
    "DATASET_PATH = '../inputs/CO_LSP_train2016.json'\n",
    "## IMAGES_PATH: path of the actual images of LSP\n",
    "IMAGES_PATH = '/home/mronchi/Datasets/lsp/lsp_dataset/images/'\n",
    "## SAVE_PATH: path of the folder to save the resulting model data\n",
    "SAVE_PATH       = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters for model\n",
    "\n",
    "# flags to save the data used during training and the partial models\n",
    "save_dataset        = True\n",
    "save_partial_models = False\n",
    "\n",
    "# number of latent factors to learn\n",
    "num_factors = 10\n",
    "\n",
    "# activities to include in the analysis\n",
    "#   - 'athletics'\n",
    "#   - 'badminton'\n",
    "#   - 'baseball'\n",
    "#   - 'gymnastics'\n",
    "#   - 'parkour'\n",
    "#   - 'soccer'\n",
    "#   - 'tennis'\n",
    "#   - 'volleyball'\n",
    "#   - 'other'\n",
    "activities = ['athletics', 'badminton', 'soccer', 'tennis', 'volleyball', 'baseball']\n",
    "\n",
    "# model that should be used to learn the basis pose factorization\n",
    "#   - 'svd':\n",
    "#   - 'bucketed_svd_2d':\n",
    "#   - 'bucketed_svd_3d':\n",
    "#   - 'lfa_2d':\n",
    "#   - 'lfa_3d':\n",
    "model_type = 'lfa_3d'\n",
    "\n",
    "# initialization for the U and V matrices in the lfa3d model\n",
    "#   - 'random':\n",
    "#   - 'svd':\n",
    "init_type = 'random'\n",
    "\n",
    "# type of angle annotations for initializing the angle of view of each pose\n",
    "#   - 'random':\n",
    "#   - 'heuristic':\n",
    "#   - 'coarse':\n",
    "#   - 'gt':\n",
    "bucketing_metric = 'gt'\n",
    "\n",
    "# number of pose clusters to use for discretizing the angles of view\n",
    "num_buckets = 8\n",
    "\n",
    "# objective function for the stochastic gradient descent\n",
    "#   - 'l1_reg':\n",
    "#   - 'l2_reg':\n",
    "#   - 'l2_l1_ista_reg':\n",
    "objective_f_type = 'l2_l1_ista_reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set hyper parameters for model\n",
    "\n",
    "hyper_params = dict()\n",
    "hyper_params['l_rate_U']           = 1e-4\n",
    "hyper_params['l_rate_V']           = 1e-4\n",
    "hyper_params['m_rate_U']           = 1e-5\n",
    "hyper_params['m_rate_V']           = 1e-5\n",
    "hyper_params['l_rate_theta']       = 1e-5\n",
    "hyper_params['m_rate_theta']       = 1e-6\n",
    "hyper_params['positive_V_flag']    = True\n",
    "hyper_params['rmse_tolerance']     = 1e-5\n",
    "hyper_params['lr_decay']           = 0.5\n",
    "hyper_params['obj_func_tolerance'] = 1e4\n",
    "hyper_params['UV_batch_step']      = 1e3\n",
    "hyper_params['theta_batch_step']   = 1e3\n",
    "hyper_params['lr_bound']           = 1e-6\n",
    "hyper_params['max_iter']           = int(1e7)\n",
    "hyper_params['error_window']       = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "\n",
    "train_model_obj = train_model(\n",
    "                    # path to the dataset json file and images\n",
    "                    dataset_path=DATASET_PATH, images_path=IMAGES_PATH,\n",
    "                    # path at which models are saved and flags\n",
    "                    save_path=SAVE_PATH, save_dataset=save_dataset,\n",
    "                    save_partial_models=save_partial_models,\n",
    "                    # number of latent factors\n",
    "                    num_factors=num_factors,\n",
    "                    # actions to exclude from the analysis\n",
    "                    activity_list=activities,\n",
    "                    # model type trained\n",
    "                    model_type=model_type,\n",
    "                    # initialization for lfa3d model\n",
    "                    init_type=init_type,\n",
    "                    # type of angle bucketing (heuristic, random or gt based)\n",
    "                    bucketing_metric=bucketing_metric,\n",
    "                    # number of buckets to cluster poses\n",
    "                    num_buckets=num_buckets,\n",
    "                    # objective function type for the SGD procedures\n",
    "                    objective_f_type=objective_f_type,\n",
    "                    # a dictionary containing all the optimization hyperparams\n",
    "                    hyper_params=hyper_params,\n",
    "                    # provide an input matrix for U\n",
    "                    U_test=None\n",
    "                )\n",
    "\n",
    "# set to True to train from scratch or with different parameters\n",
    "train = False\n",
    "if train:\n",
    "    train_model_obj.train()\n",
    "else:\n",
    "    pretrained_timestamp = ''\n",
    "    train_model_obj.load(pretrained_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class used for plotting and saving the learned movemes\n",
    "# inputs:\n",
    "#  - the trained obj: train_model_obj\n",
    "#  - color list: for coloring the skeleton\n",
    "#  - basis_coeff: a multiplying factor for moveme strength\n",
    "#                 (not used for lfa3d or lfa2d)\n",
    "# output:\n",
    "#  - None, saves the movemes at the path specified in the train_model_obj\n",
    "colors = ['g',\n",
    "           'g',\n",
    "           'y',\n",
    "           'y',\n",
    "           'r',\n",
    "           'b',\n",
    "           'r',\n",
    "           'b',\n",
    "           'y',\n",
    "           'y',\n",
    "           'm',\n",
    "           'c',\n",
    "           'm',\n",
    "           'c']\n",
    "utility_obj = utilities(train_model_obj, colors, basis_coeff=1)\n",
    "utility_obj.plot_movemes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
